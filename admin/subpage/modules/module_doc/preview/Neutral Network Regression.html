<html>
  <head>
	  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>i5ting_ztree_toc:Neutral Network Regression</title>
		<link href="toc/style/github-bf51422f4bb36427d391e4b75a1daa083c2d840e.css" media="all" rel="stylesheet" type="text/css"/>
		<link href="toc/style/github2-d731afd4f624c99a4b19ad69f3083cd6d02b81d5.css" media="all" rel="stylesheet" type="text/css"/>
		<link href="toc/css/zTreeStyle/zTreeStyle.css" media="all" rel="stylesheet" type="text/css"/>
	  <style>
		pre {
		    counter-reset: line-numbering;
		    border: solid 1px #d9d9d9;
		    border-radius: 0;
		    background: #fff;
		    padding: 0;
		    line-height: 23px;
		    margin-bottom: 30px;
		    white-space: pre;
		    overflow-x: auto;
		    word-break: inherit;
		    word-wrap: inherit;
		}

		pre a::before {
		  content: counter(line-numbering);
		  counter-increment: line-numbering;
		  padding-right: 1em; /* space after numbers */
		  width: 25px;
		  text-align: right;
		  opacity: 0.7;
		  display: inline-block;
		  color: #aaa;
		  background: #eee;
		  margin-right: 16px;
		  padding: 2px 10px;
		  font-size: 13px;
		  -webkit-touch-callout: none;
		  -webkit-user-select: none;
		  -khtml-user-select: none;
		  -moz-user-select: none;
		  -ms-user-select: none;
		  user-select: none;
		}

		pre a:first-of-type::before {
		  padding-top: 10px;
		}

		pre a:last-of-type::before {
		  padding-bottom: 10px;
		}

		pre a:only-of-type::before {
		  padding: 10px;
		}

		.highlight { background-color: #ffffcc } /* RIGHT */
		</style>
  </head>
  <body>
	  <div>
				<div style='width:25%;'>
						<ul id="tree" class="ztree" style='width:100%'>

						</ul>
				</div>
        <div id='readme' style='width:70%;margin-left:20%;'>
          	<article class='markdown-body'>
            	<h1 id="neutral-network-regression">Neutral Network Regression</h1>
<h2 id="detailed-info">Detailed Info</h2>
<h3 id="description">Description</h3>
<p>&#39;Multi-layer Perceptron regressor.    This model opt\n             imizes the squared-loss using LBFGS or stochastic \n             gradient    descent.&#39;</p>
<table>
<thead>
<tr>
<th>category</th>
<th>sub_category</th>
<th>type</th>
<th>cpu</th>
<th>gpu</th>
<th>memory</th>
<th>pipe_status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Machine Learning</td>
<td>Regression</td>
<td>DOCKER</td>
<td>1</td>
<td>0</td>
<td>2048</td>
<td>keep</td>
</tr>
</tbody>
</table>
<h3 id="parameter-detail">Parameter Detail</h3>
<table>
<thead>
<tr>
<th>name</th>
<th>is_input</th>
<th>category</th>
<th>default</th>
<th>required</th>
<th>selector_model</th>
</tr>
</thead>
<tbody>
<tr>
<td>label</td>
<td>True</td>
<td>STRING</td>
<td></td>
<td>True</td>
<td>SINGLE</td>
</tr>
<tr>
<td>input_file1</td>
<td>True</td>
<td>FILE</td>
<td></td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>hidden_layer_sizes</td>
<td>True</td>
<td>STRING</td>
<td>100</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>activation</td>
<td>True</td>
<td>STRING</td>
<td>relu</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>solver</td>
<td>True</td>
<td>STRING</td>
<td>adam</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>alpha</td>
<td>True</td>
<td>STRING</td>
<td>0.0001</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>True</td>
<td>STRING</td>
<td>auto</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>learning_rate</td>
<td>True</td>
<td>STRING</td>
<td>constant</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>learning_rate_init</td>
<td>True</td>
<td>STRING</td>
<td>0.001</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>power_t</td>
<td>True</td>
<td>STRING</td>
<td>0.5</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>max_iter</td>
<td>True</td>
<td>STRING</td>
<td>200</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>shuffle</td>
<td>True</td>
<td>STRING</td>
<td>True</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>tol</td>
<td>True</td>
<td>STRING</td>
<td>0.0001</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>momentum</td>
<td>True</td>
<td>STRING</td>
<td>0.9</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>early_stopping</td>
<td>True</td>
<td>STRING</td>
<td>False</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>output_model_file</td>
<td>False</td>
<td>FILE</td>
<td></td>
<td>False</td>
<td>None</td>
</tr>
<tr>
<td>output_model</td>
<td>False</td>
<td>DIRECTORY</td>
<td>module</td>
<td>False</td>
<td>None</td>
</tr>
</tbody>
</table>
<h1 id="detailed-info-of-parameters">Detailed Info of Parameters</h1>
<h2 id="input-parameters">Input Parameters</h2>
<h3 id="1-label">1.label</h3>
<p>&#39;target feature&#39;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td></td>
<td>Yes</td>
<td>SINGLE</td>
<td>input_file1</td>
</tr>
</tbody>
</table>
<h3 id="2-input_file1">2.input_file1</h3>
<p>&#39;input csv file for trainer&#39;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>FILE</td>
<td></td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="3-hidden_layer_sizes">3.hidden_layer_sizes</h3>
<p>&#39;The ith element represents the number of neurons in\n              the ith        hidden layer.&#39;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>100</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="4-activation">4.activation</h3>
<p>&quot;Activation function for the hidden layer.        - \n             &#39;identity&#39;, no-op activation, useful to implement \n             linear bottleneck,          returns f(x) = x      \n               - &#39;logistic&#39;, the logistic sigmoid function,    \n                   returns f(x) = 1 / (1 + exp(-x)).        - &#39;\n             tanh&#39;, the hyperbolic tan function,          retur\n             ns f(x) = tanh(x).        - &#39;relu&#39;, the rectified \n             linear unit function,          returns f(x) = max(\n             0, x)&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>relu</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<ul>
<li>choices</li>
</ul>
<table>
<thead>
<tr>
<th>choice</th>
<th>help</th>
</tr>
</thead>
<tbody>
<tr>
<td>identity</td>
<td></td>
</tr>
<tr>
<td>logistic</td>
<td></td>
</tr>
<tr>
<td>tanh</td>
<td></td>
</tr>
<tr>
<td>relu</td>
</tr>
</tbody>
</table>
<h3 id="5-solver">5.solver</h3>
<p>&quot;The solver for weight optimization.        - &#39;lbfgs\n             &#39; is an optimizer in the family of quasi-Newton me\n             thods.        - &#39;sgd&#39; refers to stochastic gradien\n             t descent.        - &#39;adam&#39; refers to a stochastic \n             gradient-based optimizer proposed          by King\n             ma, Diederik, and Jimmy Ba        Note: The defaul\n             t solver &#39;adam&#39; works pretty well on relatively   \n                  large datasets (with thousands of training sa\n             mples or more) in terms of        both training ti\n             me and validation score.        For small datasets\n             , however, &#39;lbfgs&#39; can converge faster and perform\n                     better.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>adam</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<ul>
<li>choices</li>
</ul>
<table>
<thead>
<tr>
<th>choice</th>
<th>help</th>
</tr>
</thead>
<tbody>
<tr>
<td>lbfgs</td>
<td></td>
</tr>
<tr>
<td>sgd</td>
<td></td>
</tr>
<tr>
<td>adam</td>
</tr>
</tbody>
</table>
<h3 id="6-alpha">6.alpha</h3>
<p>&#39;L2 penalty (regularization term) parameter.&#39;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.0001</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="7-batch_size">7.batch_size</h3>
<p>&#39;Size of minibatches for stochastic optimizers.     \n                If the solver is \&#39;lbfgs\&#39;, the classifier will n\n             ot use minibatch.        When set to &quot;auto&quot;, <code>batc\n             h_size=min(200, n_samples)</code>&#39;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>auto</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="8-learning_rate">8.learning_rate</h3>
<p>&quot;Learning rate schedule for weight updates.        -\n              &#39;constant&#39; is a constant learning rate given by  \n                     &#39;learning_rate_init&#39;.        - &#39;invscaling\n             &#39; gradually decreases the learning rate at each   \n                    time step &#39;t&#39; using an inverse scaling expo\n             nent of &#39;power_t&#39;.          effective_learning_rat\n             e = learning_rate_init / pow(t, power_t)        - \n             &#39;adaptive&#39; keeps the learning rate constant to    \n                   &#39;learning_rate_init&#39; as long as training los\n             s keeps decreasing.          Each time two consecu\n             tive epochs fail to decrease training loss by at  \n                     least tol, or fail to increase validation \n             score by at least tol if          &#39;early_stopping&#39;\n              is on, the current learning rate is divided by 5.\n                     Only used when <code>solver=&#39;sgd&#39;</code>.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>constant</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<ul>
<li>choices</li>
</ul>
<table>
<thead>
<tr>
<th>choice</th>
<th>help</th>
</tr>
</thead>
<tbody>
<tr>
<td>constant</td>
<td></td>
</tr>
<tr>
<td>invscaling</td>
<td></td>
</tr>
<tr>
<td>adaptive</td>
</tr>
</tbody>
</table>
<h3 id="9-learning_rate_init">9.learning_rate_init</h3>
<p>&quot;The initial learning rate used. It controls the ste\n             p-size        in updating the weights. Only used w\n             hen solver=&#39;sgd&#39; or &#39;adam&#39;.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.001</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="10-power_t">10.power_t</h3>
<p>&quot;The exponent for inverse scaling learning rate.    \n                 It is used in updating effective learning rate\n              when the learning_rate        is set to &#39;invscali\n             ng&#39;. Only used when solver=&#39;sgd&#39;.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.5</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="11-max_iter">11.max_iter</h3>
<p>&quot;Maximum number of iterations. The solver iterates u\n             ntil convergence        (determined by &#39;tol&#39;) or t\n             his number of iterations. For stochastic        so\n             lvers (&#39;sgd&#39;, &#39;adam&#39;), note that this determines t\n             he number of epochs        (how many times each da\n             ta point will be used), not the number of        g\n             radient steps.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>200</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="12-shuffle">12.shuffle</h3>
<p>&quot;Whether to shuffle samples in each iteration. Only \n             used when        solver=&#39;sgd&#39; or &#39;adam&#39;.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>True</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="13-tol">13.tol</h3>
<p>&quot;Tolerance for the optimization. When the loss or sc\n             ore is not improving        by at least <code>tol</code> fo\n             r <code>n_iter_no_change</code> consecutive iterations,    \n                 unless <code>learning_rate</code> is set to &#39;adaptive&#39;,\n              convergence is        considered to be reached an\n             d training stops.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.0001</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="14-momentum">14.momentum</h3>
<p>&quot;Momentum for gradient descent update. Should be bet\n             ween 0 and 1. Only        used when solver=&#39;sgd&#39;.&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.9</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="15-early_stopping">15.early_stopping</h3>
<p>&quot;Whether to use early stopping to terminate training\n              when validation        score is not improving. If\n              set to true, it will automatically set        asi\n             de 10% of training data as validation and terminat\n             e training when        validation score is not imp\n             roving by at least tol for        <code>n_iter_no_chan\n             ge</code> consecutive epochs. The split is stratified, \n                    except in a multilabel setting.        Only\n              effective when solver=&#39;sgd&#39; or &#39;adam&quot;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>False</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h2 id="output-parameters">Output Parameters</h2>
<h3 id="1-output_model_file">1.output_model_file</h3>
<p>&#39;output module&#39;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>FILE</td>
<td></td>
<td>No</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="2-output_model">2.output_model</h3>
<p>&#39;output module&#39;</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>DIRECTORY</td>
<td>module</td>
<td>No</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h1 id="test-case">Test Case</h1>
<h2 id="case1">Case1</h2>
<h2 id="desc-">Desc:波士顿房价多层感知机回归</h2>
<h3 id="input-params">Input Params</h3>
<table>
<thead>
<tr>
<th>field</th>
<th>value</th>
<th>desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>label</td>
<td>PRICE</td>
<td>标签</td>
</tr>
<tr>
<td>hidden_layer_sizes</td>
<td>100</td>
<td>隐层大小设置成100</td>
</tr>
<tr>
<td>activation</td>
<td>relu</td>
<td>选用relu激活函数</td>
</tr>
<tr>
<td>solver</td>
<td>adam</td>
<td>优化器选用adam算法优化</td>
</tr>
<tr>
<td>alpha</td>
<td>0.0001</td>
<td>l2正则惩罚力度alpha设置为0.0001</td>
</tr>
<tr>
<td>batch_size</td>
<td>auto</td>
<td>每次训练数据放入的数据量,默认auto即可,每次训练200条数据</td>
</tr>
<tr>
<td>learning_rate</td>
<td>constant</td>
<td>学习率保持为常量,和初始学习率一致</td>
</tr>
<tr>
<td>learning_rate_init</td>
<td>0.001</td>
<td>初始学习率设置成0.001</td>
</tr>
<tr>
<td>power_t</td>
<td>0.5</td>
<td>由于学习率下降的策略没有指定,学习率仅仅指定为常量,sgd策略中的下降力度参数不生效</td>
</tr>
<tr>
<td>max_iter</td>
<td>200</td>
<td>最大迭代次数限制为200</td>
</tr>
<tr>
<td>shuffle</td>
<td>True</td>
<td>每次迭代把数据打乱</td>
</tr>
<tr>
<td>tol</td>
<td>0.0001</td>
<td>梯度下降变化停止阈值设置小一点:0.0001</td>
</tr>
<tr>
<td>momentum</td>
<td>0.9</td>
<td>梯度更新动力参数:由于策略不为sgd,这个参数此处不生效</td>
</tr>
<tr>
<td>early_stopping</td>
<td>False</td>
<td>不采用早停策略</td>
</tr>
</tbody>
</table>
<h3 id="post-json-format">Post Json Format</h3>
<table>
<thead>
<tr>
<th>CRIM</th>
<th>ZN</th>
<th>INDUS</th>
<th>CHAS</th>
<th>NOX</th>
<th>RM</th>
<th>AGE</th>
<th>DIS</th>
<th>RAD</th>
<th>TAX</th>
<th>PTRATIO</th>
<th>B</th>
<th>LSTAT</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.00632</td>
<td>18.0</td>
<td>2.31</td>
<td>0</td>
<td>0.5379999999999999</td>
<td>6.575</td>
<td>65.2</td>
<td>4.09</td>
<td>1</td>
<td>296</td>
<td>15.3</td>
<td>396.9</td>
<td>4.98</td>
</tr>
</tbody>
</table>
<h3 id="custom-test-report">Custom Test Report</h3>
<ul>
<li>Test Example</li>
</ul>
<table>
<thead>
<tr>
<th>field</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>CRIM</td>
<td>0.00632</td>
</tr>
<tr>
<td>ZN</td>
<td>18.0</td>
</tr>
<tr>
<td>INDUS</td>
<td>2.31</td>
</tr>
<tr>
<td>CHAS</td>
<td>0.0</td>
</tr>
<tr>
<td>NOX</td>
<td>0.5379999999999999</td>
</tr>
<tr>
<td>RM</td>
<td>6.575</td>
</tr>
<tr>
<td>AGE</td>
<td>65.2</td>
</tr>
<tr>
<td>DIS</td>
<td>4.09</td>
</tr>
<tr>
<td>RAD</td>
<td>1.0</td>
</tr>
<tr>
<td>TAX</td>
<td>296.0</td>
</tr>
<tr>
<td>PTRATIO</td>
<td>15.3</td>
</tr>
<tr>
<td>B</td>
<td>396.9</td>
</tr>
<tr>
<td>LSTAT</td>
<td>4.98</td>
</tr>
</tbody>
</table>
<ul>
<li>Predict Result</li>
</ul>
<table>
<thead>
<tr>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td>{&#39;result&#39;: &#39;29.649208236011518&#39;}</td>
</tr>
</tbody>
</table>

          	</article>
        </div>
		</div>
  </body>
</html>
<script type="text/javascript" src="toc/js/jquery-1.4.4.min.js"></script>
<script type="text/javascript" src="toc/js/jquery.ztree.all-3.5.min.js"></script>
<script type="text/javascript" src="toc/js/ztree_toc.js"></script>
<script type="text/javascript" src="toc_conf.js"></script>

<SCRIPT type="text/javascript" >
<!--
$(document).ready(function(){
    var css_conf = eval(markdown_panel_style);
    $('#readme').css(css_conf)
    
    var conf = eval(jquery_ztree_toc_opts);
		$('#tree').ztree_toc(conf);
});
//-->
</SCRIPT>