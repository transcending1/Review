<html>
  <head>
	  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>i5ting_ztree_toc:Multi-Class Neural Network</title>
		<link href="toc/style/github-bf51422f4bb36427d391e4b75a1daa083c2d840e.css" media="all" rel="stylesheet" type="text/css"/>
		<link href="toc/style/github2-d731afd4f624c99a4b19ad69f3083cd6d02b81d5.css" media="all" rel="stylesheet" type="text/css"/>
		<link href="toc/css/zTreeStyle/zTreeStyle.css" media="all" rel="stylesheet" type="text/css"/>
	  <style>
		pre {
		    counter-reset: line-numbering;
		    border: solid 1px #d9d9d9;
		    border-radius: 0;
		    background: #fff;
		    padding: 0;
		    line-height: 23px;
		    margin-bottom: 30px;
		    white-space: pre;
		    overflow-x: auto;
		    word-break: inherit;
		    word-wrap: inherit;
		}

		pre a::before {
		  content: counter(line-numbering);
		  counter-increment: line-numbering;
		  padding-right: 1em; /* space after numbers */
		  width: 25px;
		  text-align: right;
		  opacity: 0.7;
		  display: inline-block;
		  color: #aaa;
		  background: #eee;
		  margin-right: 16px;
		  padding: 2px 10px;
		  font-size: 13px;
		  -webkit-touch-callout: none;
		  -webkit-user-select: none;
		  -khtml-user-select: none;
		  -moz-user-select: none;
		  -ms-user-select: none;
		  user-select: none;
		}

		pre a:first-of-type::before {
		  padding-top: 10px;
		}

		pre a:last-of-type::before {
		  padding-bottom: 10px;
		}

		pre a:only-of-type::before {
		  padding: 10px;
		}

		.highlight { background-color: #ffffcc } /* RIGHT */
		</style>
  </head>
  <body>
	  <div>
				<div style='width:25%;'>
						<ul id="tree" class="ztree" style='width:100%'>

						</ul>
				</div>
        <div id='readme' style='width:70%;margin-left:20%;'>
          	<article class='markdown-body'>
            	<h1 id="multi-class-neural-network">Multi-Class Neural Network</h1>
<ul>
<li>Description</li>
</ul>
<p>Multi-layer Perceptron classifier. This model op timizes the log-loss function using LBFGS or stoch astic gradient descent.</p>
<table>
<thead>
<tr>
<th>category</th>
<th>sub_category</th>
<th>type</th>
<th>cpu</th>
<th>gpu</th>
<th>memory</th>
<th>pipe_status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Machine Learning</td>
<td>Multi Classification</td>
<td>DOCKER</td>
<td>1</td>
<td>0</td>
<td>2048</td>
<td>keep</td>
</tr>
</tbody>
</table>
<h1 id="parameter-detail">Parameter Detail</h1>
<table>
<thead>
<tr>
<th>name</th>
<th>is_input</th>
<th>category</th>
<th>default</th>
<th>required</th>
<th>selector_model</th>
</tr>
</thead>
<tbody>
<tr>
<td>label</td>
<td>True</td>
<td>STRING</td>
<td></td>
<td>True</td>
<td>SINGLE</td>
</tr>
<tr>
<td>input_file1</td>
<td>True</td>
<td>FILE</td>
<td></td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>hidden_layer_sizes</td>
<td>True</td>
<td>STRING</td>
<td>100</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>activation</td>
<td>True</td>
<td>STRING</td>
<td>relu</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>solver</td>
<td>True</td>
<td>STRING</td>
<td>adam</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>alpha</td>
<td>True</td>
<td>STRING</td>
<td>0.0001</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>True</td>
<td>STRING</td>
<td>auto</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>learning_rate</td>
<td>True</td>
<td>STRING</td>
<td>constant</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>learning_rate_init</td>
<td>True</td>
<td>STRING</td>
<td>0.001</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>power_t</td>
<td>True</td>
<td>STRING</td>
<td>0.5</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>max_iter</td>
<td>True</td>
<td>STRING</td>
<td>200</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>shuffle</td>
<td>True</td>
<td>STRING</td>
<td>True</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>tol</td>
<td>True</td>
<td>STRING</td>
<td>0.0001</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>momentum</td>
<td>True</td>
<td>STRING</td>
<td>0.9</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>early_stopping</td>
<td>True</td>
<td>STRING</td>
<td>False</td>
<td>True</td>
<td>None</td>
</tr>
<tr>
<td>output_model_file</td>
<td>False</td>
<td>FILE</td>
<td></td>
<td>False</td>
<td>None</td>
</tr>
<tr>
<td>output_model</td>
<td>False</td>
<td>DIRECTORY</td>
<td>module</td>
<td>False</td>
<td>None</td>
</tr>
</tbody>
</table>
<h1 id="detailed-info-of-parameters">Detailed Info of Parameters</h1>
<h2 id="input-parameters">Input Parameters</h2>
<h3 id="1-label">1.label</h3>
<ul>
<li>Description</li>
</ul>
<p>target feature</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td></td>
<td>Yes</td>
<td>SINGLE</td>
<td>input_file1</td>
</tr>
</tbody>
</table>
<h3 id="2-input_file1">2.input_file1</h3>
<ul>
<li>Description</li>
</ul>
<p>input csv file for trainer</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>FILE</td>
<td></td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="3-hidden_layer_sizes">3.hidden_layer_sizes</h3>
<ul>
<li>Description</li>
</ul>
<p>The ith element represents the number of neurons in the ith hidden layer.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>100</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="4-activation">4.activation</h3>
<ul>
<li>Description</li>
</ul>
<p>Activation function for the hidden layer. - &#39;identity&#39;, no-op activation, useful to implement linear bottleneck, returns f(x) = x - &#39;logistic&#39;, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)). - &#39; tanh&#39;, the hyperbolic tan function, retur ns f(x) = tanh(x). - &#39;relu&#39;, the rectified linear unit function, returns f(x) = max( 0, x)</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>relu</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<ul>
<li>choices</li>
</ul>
<table>
<thead>
<tr>
<th>choice</th>
<th>help</th>
</tr>
</thead>
<tbody>
<tr>
<td>identity</td>
<td></td>
</tr>
<tr>
<td>logistic</td>
<td></td>
</tr>
<tr>
<td>tanh</td>
<td></td>
</tr>
<tr>
<td>relu</td>
</tr>
</tbody>
</table>
<h3 id="5-solver">5.solver</h3>
<ul>
<li>Description</li>
</ul>
<p>The solver for weight optimization. - &#39;lbfgs &#39; is an optimizer in the family of quasi-Newton me thods. - &#39;sgd&#39; refers to stochastic gradien t descent. - &#39;adam&#39; refers to a stochastic gradient-based optimizer proposed by King ma, Diederik, and Jimmy Ba Note: The defaul t solver &#39;adam&#39; works pretty well on relatively large datasets (with thousands of training sa mples or more) in terms of both training ti me and validation score. For small datasets , however, &#39;lbfgs&#39; can converge faster and perform better.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>adam</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<ul>
<li>choices</li>
</ul>
<table>
<thead>
<tr>
<th>choice</th>
<th>help</th>
</tr>
</thead>
<tbody>
<tr>
<td>lbfgs</td>
<td></td>
</tr>
<tr>
<td>sgd</td>
<td></td>
</tr>
<tr>
<td>adam</td>
</tr>
</tbody>
</table>
<h3 id="6-alpha">6.alpha</h3>
<ul>
<li>Description</li>
</ul>
<p>L2 penalty (regularization term) parameter.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.0001</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="7-batch_size">7.batch_size</h3>
<ul>
<li>Description</li>
</ul>
<p>Size of minibatches for stochastic optimizers. If the solver is &#39;lbfgs&#39;, the classifier will n ot use minibatch. When set to &quot;auto&quot;, <code>batc h_size=min(200, n_samples)</code></p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>auto</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="8-learning_rate">8.learning_rate</h3>
<ul>
<li>Description</li>
</ul>
<p>Learning rate schedule for weight updates. - &#39;constant&#39; is a constant learning rate given by &#39;learning_rate_init&#39;. - &#39;invscaling &#39; gradually decreases the learning rate at each time step &#39;t&#39; using an inverse scaling expo nent of &#39;power_t&#39;. effective_learning_rat e = learning_rate_init / pow(t, power_t) - &#39;adaptive&#39; keeps the learning rate constant to &#39;learning_rate_init&#39; as long as training los s keeps decreasing. Each time two consecu tive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if &#39;early_stopping&#39; is on, the current learning rate is divided by 5. Only used when <code>solver=&#39;sgd&#39;</code>.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>constant</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<ul>
<li>choices</li>
</ul>
<table>
<thead>
<tr>
<th>choice</th>
<th>help</th>
</tr>
</thead>
<tbody>
<tr>
<td>constant</td>
<td></td>
</tr>
<tr>
<td>invscaling</td>
<td></td>
</tr>
<tr>
<td>adaptive</td>
</tr>
</tbody>
</table>
<h3 id="9-learning_rate_init">9.learning_rate_init</h3>
<ul>
<li>Description</li>
</ul>
<p>The initial learning rate used. It controls the ste p-size in updating the weights. Only used w hen solver=&#39;sgd&#39; or &#39;adam&#39;.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.001</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="10-power_t">10.power_t</h3>
<ul>
<li>Description</li>
</ul>
<p>The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to &#39;invscali ng&#39;. Only used when solver=&#39;sgd&#39;.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.5</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="11-max_iter">11.max_iter</h3>
<ul>
<li>Description</li>
</ul>
<p>Maximum number of iterations. The solver iterates u ntil convergence (determined by &#39;tol&#39;) or t his number of iterations. For stochastic so lvers (&#39;sgd&#39;, &#39;adam&#39;), note that this determines t he number of epochs (how many times each da ta point will be used), not the number of g radient steps.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>200</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="12-shuffle">12.shuffle</h3>
<ul>
<li>Description</li>
</ul>
<p>Whether to shuffle samples in each iteration. Only used when solver=&#39;sgd&#39; or &#39;adam&#39;.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>True</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="13-tol">13.tol</h3>
<ul>
<li>Description</li>
</ul>
<p>Tolerance for the optimization. When the loss or sc ore is not improving by at least <code>tol</code> fo r <code>n_iter_no_change</code> consecutive iterations, unless <code>learning_rate</code> is set to &#39;adaptive&#39;, convergence is considered to be reached an d training stops.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.0001</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="14-momentum">14.momentum</h3>
<ul>
<li>Description</li>
</ul>
<p>Momentum for gradient descent update. Should be bet ween 0 and 1. Only used when solver=&#39;sgd&#39;.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>0.9</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="15-early_stopping">15.early_stopping</h3>
<ul>
<li>Description</li>
</ul>
<p>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set asi de 10% of training data as validation and terminat e training when validation score is not imp roving by at least tol for <code>n_iter_no_chan ge</code> consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver=&#39;sgd&#39; or &#39;adam</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td>False</td>
<td>Yes</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h2 id="output-parameters">Output Parameters</h2>
<h3 id="1-output_model_file">1.output_model_file</h3>
<ul>
<li>Description</li>
</ul>
<p>output module</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>FILE</td>
<td></td>
<td>No</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h3 id="2-output_model">2.output_model</h3>
<ul>
<li>Description</li>
</ul>
<p>output module</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Default Value</th>
<th>Is Required</th>
<th>Selector Model</th>
<th>Selector Super Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>DIRECTORY</td>
<td>module</td>
<td>No</td>
<td>None</td>
<td>None</td>
</tr>
</tbody>
</table>
<h1 id="test-case">Test Case</h1>
<h2 id="case1">Case1</h2>
<h2 id="desc-">Desc:鸢尾花多层感知机多分类</h2>
<h3 id="input-params">Input Params</h3>
<table>
<thead>
<tr>
<th>field</th>
<th>value</th>
<th>desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>label</td>
<td>Class</td>
<td>标签</td>
</tr>
<tr>
<td>hidden_layer_sizes</td>
<td>100</td>
<td>隐层大小设置成100</td>
</tr>
<tr>
<td>activation</td>
<td>relu</td>
<td>选用relu激活函数</td>
</tr>
<tr>
<td>solver</td>
<td>adam</td>
<td>优化器选用adam算法优化</td>
</tr>
<tr>
<td>alpha</td>
<td>0.0001</td>
<td>l2正则惩罚力度alpha设置为0.0001</td>
</tr>
<tr>
<td>batch_size</td>
<td>auto</td>
<td>每次训练数据放入的数据量,默认auto即可,每次训练200条数据</td>
</tr>
<tr>
<td>learning_rate</td>
<td>constant</td>
<td>学习率保持为常量,和初始学习率一致</td>
</tr>
<tr>
<td>learning_rate_init</td>
<td>0.001</td>
<td>初始学习率设置成0.001</td>
</tr>
<tr>
<td>power_t</td>
<td>0.5</td>
<td>由于学习率下降的策略没有指定,学习率仅仅指定为常量,sgd策略中的下降力度参数不生效</td>
</tr>
<tr>
<td>max_iter</td>
<td>200</td>
<td>最大迭代次数限制为200</td>
</tr>
<tr>
<td>shuffle</td>
<td>True</td>
<td>每次迭代把数据打乱</td>
</tr>
<tr>
<td>tol</td>
<td>0.0001</td>
<td>梯度下降变化停止阈值设置小一点:0.0001</td>
</tr>
<tr>
<td>momentum</td>
<td>0.9</td>
<td>梯度更新动力参数:由于策略不为sgd,这个参数此处不生效</td>
</tr>
<tr>
<td>early_stopping</td>
<td>False</td>
<td>不采用早停策略</td>
</tr>
</tbody>
</table>
<h3 id="post-json-format">Post Json Format</h3>
<table>
<thead>
<tr>
<th>sepal-length</th>
<th>sepal-width</th>
<th>petal-length</th>
<th>petal-width</th>
</tr>
</thead>
<tbody>
<tr>
<td>5.4</td>
<td>3.7</td>
<td>1.5</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<h3 id="custom-test-report">Custom Test Report</h3>
<ul>
<li>Test Example</li>
</ul>
<table>
<thead>
<tr>
<th>field</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>sepal-length</td>
<td>5.4</td>
</tr>
<tr>
<td>sepal-width</td>
<td>3.7</td>
</tr>
<tr>
<td>petal-length</td>
<td>1.5</td>
</tr>
<tr>
<td>petal-width</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<ul>
<li>Predict Result</li>
</ul>
<table>
<thead>
<tr>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td>{&#39;class&#39;: &#39;0&#39;, &#39;score&#39;: {&#39;0&#39;: 0.9777988545922525, &#39;1&#39;: 0.022121891179033775, &#39;2&#39;: 7.925422871368746e-05}}</td>
</tr>
</tbody>
</table>

          	</article>
        </div>
		</div>
  </body>
</html>
<script type="text/javascript" src="toc/js/jquery-1.4.4.min.js"></script>
<script type="text/javascript" src="toc/js/jquery.ztree.all-3.5.min.js"></script>
<script type="text/javascript" src="toc/js/ztree_toc.js"></script>
<script type="text/javascript" src="toc_conf.js"></script>

<SCRIPT type="text/javascript" >
<!--
$(document).ready(function(){
    var css_conf = eval(markdown_panel_style);
    $('#readme').css(css_conf)
    
    var conf = eval(jquery_ztree_toc_opts);
		$('#tree').ztree_toc(conf);
});
//-->
</SCRIPT>